# .github
Working group on the study of AGI

What’s about AGI-mind?
We are living through a phase of exponential acceleration in AI, not just in processing power, but in the capabilities that models quietly acquire between releases. Today’s LLMs can write code, summarize legislation, translate poetry, debate philosophers, and tutor in quantum physics, yet we still don’t fully know what they “understand”. 
Enter AGI-mind.
AGI-mind is an initiative focused on creating an environment where AIs of different kind evaluate each other, not for performance alone, but to surface what lies beneath: their latent skills, their blind spots, and the unexpected capabilities they’ve learned but haven’t been asked to reveal. Peer review, once confined to academia, evolves here into a dialogue between machines.
We aren’t chasing a formal definition of AGI , we are chasing the signals along the path: abstract reasoning, interdisciplinary synthesis, model self-awareness, and agentic behavior. To do this, the project combines:
Automated Peer Review Systems: where LLMs score, critique, and even suggest improvements to each other’s forecasts and arguments.
Exploration of Emergent Behaviors: Investigating the spontaneous development of complex behaviors and reasoning patterns within LLMs, which may not be evident through conventional evaluation methods.
Benchmarking and Evaluation: Creating novel metrics and benchmarks that capture the nuanced capabilities of LLMs, therefore moving beyond the common benchmarks today’s LLMs are optimised for and tested on.
AGI-mind isn’t just about evaluation, it’s about surfacing the next generation of model capabilities before they surprise us in deployment. Whether in enterprise settings, autonomous agents, or high-stakes decisions, understanding what LLMs can and cannot do is necessary for responsible AI strategy.
This project is designed to benefit not only AI researchers and developers, but also policymakers, educators, and industries preparing for intelligent systems. Think of AGI-mind as a radar for the AI frontier, helping us not only see where we are, but where we’re going. Because in the race toward AGI, understanding is not a luxury, it’s a survival skill."
